Junk food is everywhere. We're eating way too much of it. Most of us know what we're doing and yet we do it anyway.

So here's a suggestion offered by two researchers at the Rand Corporation: Why not take a lesson from alcohol control policies and apply them to where food is sold and how it's displayed?

" Many policy measures to control obesity (肥胖症) assume that people consciously and rationally choose what and how much they eat and therefore focus on providing information and more access to healthier foods," note the two researchers.

" In contrast," the researchers continue, " many regulations that don't assume people make rational choices have been successfully applied to control alcohol, a substance-like food-of which immoderate consumption leads to serious health problems. "

The research references studies of people's behavior with food and alcohol and results of alcohol restrictions, and then lists five regulations that the researchers think might be promising if applied to junk foods. Among them:

Density restrictions; licenses to sell alcohol aren't handed out unplanned to all comers but are allotted (分配) based on the number of places in an area that already sell alcohol. These make alcohol less easy to get and reduce the number of psychological cues to drink.

Similarly, the researchers say, being presented with junk food stimulates our desire to eat it. So why not limit the density of food outlets, particularly ones that sell food rich in empty calories? And why not limit sale of food in places that aren't primarily food stores?

Display and sales restrictions; California has a rule prohibiting alcohol displays near the cash registers in gas stations, and in most places you can't buy alcohol at drive-through facilities. At supermarkets, food companies pay to have their wares in places where they're easily seen. One could remove junk food to the back of the store and ban them from the shelves at checkout lines. The other measures include restricting portion sizes, taxing and prohibiting special price deals for junk foods, and placing warning labels on the products.

Kodak's decision to file for bankruptcy (破产) protection is a sad, though not unexpected, turning point for a leading American corporation that pioneered consumer photography and dominated the film market for decades, but ultimately failed to adapt to the digital revolution.

Although many attribute Kodak's downfall to " complacency (自满)," that explanation doesn't acknowledge the lengths to which the company went to reinvent itself. Decades ago, Kodak anticipated that digital photography would overtake film-and in fact, Kodak invented the first digital camera in 1975-but in a fateful decision, the company chose to shelf its new discovery to focus on its traditional film business.

It wasn't that Kodak was blind to the future, said Rebecca Henderson, a professor at Harvard Business School, but rather that it failed to execute on a strategy to confront it. By the time the company realized its mistake, it was too late.

Kodak is an example of a firm that was very much aware that they had to adapt, and spent a lot of money trying to do so, but ultimately failed. Large companies have a difficult time switching to new markets because there is a temptation to put existing assets into the new businesses.

Although Kodak anticipated the inevitable rise of digital photography, its corporate (企业的) culture was too rooted in the successes of the past for it to make the clean break necessary to fully embrace the future. They were a company stuck in time. Their history was so important to them. Now their history has become a liability.

Kodak's downfall over the last several decades was dramatic. In 1976, the company commanded 90% of the market for photographic film and 85% of the market for cameras. But the 1980s brought new competition from Japanese film company Fuji Photo, which undermined Kodak by offering lower prices for film and photo supplies. Kodak's decision not to pursue the role of official film for the 1984 Los Angeles Olympics was a major miscalculation. The bid went instead to Fuji, which exploited its sponsorship to win a permanent foothold in the marketplace.

The endless debate about " work-life balance" often contains a hopeful footnote about stay-at-home dads. If American society and business won't make it easier on future female leaders who choose to have children, there is still the ray of hope that increasing numbers of full-time fathers will. But based on today's socioeconomic trends, this hope is, unfortunately, misguided.

It's true that the number of men who have left work to do their thing as full-time parents has doubled in a decade, but it's still very small; only 0. 8% of married couples where the stay-at-home father was out of the labor force for a year. Even that percentage is likely inflated by men thrust into their caretaker role by a downsizing. This is simply not a large enough group to reduce the social stigma and force other adjustments necessary to supporting men in this decision, even if only for a relatively short time.

Even shorter times away from work for working fathers are already difficult. A study found that 85% of new fathers take some time off after the birth of a child-but for all but a few, it's a week or two at most. Meanwhile, the average for women who take leave is more than 10 weeks.

Such choices impact who moves up in the organization. While you're away, someone else is doing your work, making your sales, taking care of your customers. That can't help you at work. It can only hurt you. Women, of course, face the same issues of returning after a long absence. But with many more women than men choosing to leave the workforce entirely to raise families, returning from an extended parental leave doesn't raise as many eyebrows as it does for men.

Women would make more if they didn't break their earning trajectory (轨迹) by leaving the workforce, or if higher-paying professions were more family-friendly. In the foreseeable future, stay-at-home fathers may make all the difference for individual families, but their presence won't reduce the numbers of high-potential women who are forced to choose between family and career.

Some of the world's most significant problems never hit headlines. One example comes from agriculture. Food riots and hunger make news. But the trend lying behind these matters is rarely talked about. This is the decline in the growth in yields of some of the world's major crops. A new study by the University of Minnesota and McGill University in Montreal looks at where, and how far, this decline is occurring.

The authors take a vast number of data points for the four most important crops: rice, wheat, com and soyabeans (大豆). They find that on between 24% and 39% of all harvested areas, the improvement in yields that took place before the 1980s slowed down in the 1990s and 2000s.

There are two worrying features of the slowdown. One is that it has been particularly sharp in the world's most populous (人口多的) countries, India and China. Their ability to feed themselves has been an important source of relative stability both within the countries and on world food markets. That self-sufficiency cannot be taken for granted if yields continue to slow down or reverse.

Second, yield growth has been lower in wheat and rice than in corn and soyabeans. This is problematic because wheat and rice are more important as foods, accounting for around half of all calories consumed. Corn and soyabeans are more important as feed grains. The authors note that " we have preferentially focused our crop improvement efforts on feeding animals and cars rather than on crops that feed people and are the basis of food security in much of the world. "

The report qualifies the more optimistic findings of another new paper which suggests that the world will not have to dig up a lot more land for farming in order to feed 9 billion people in 2050, as the Food and Agriculture Organisation has argued.

Instead, it says, thanks to slowing population growth, land currently ploughed up for crops might be able to revert (返回) to forest or wilderness. This could happen. The trouble is that the forecast assumes continued improvements in yields, which may not actually happen.

If you think a high-factor sunscreen (防晒霜) keeps you safe from harmful rays, you may be wrong. Research in this week's Nature shows that while factor 50 reduces the number of melanomas (黑瘤) and delays their occurrence, it can't prevent them. Melanomas are the most aggressive skin cancers. You have a higher risk if you have red or blond hair, fair skin, blue or green eyes, or sunburn easily, or if a close relative has had one. Melanomas are more common if you have periodic intense exposure to the sun. Other skin cancers are increasingly likely with long-term exposure.

There is continuing debate as to how effective sunscreen is in reducing melanomas-the evidence is weaker than it is for preventing other types of skin cancer. A 2011 Australian study of 1,621 people found that people randomly selected to apply sunscreen daily had half the rate of melanomas of people who used cream as needed. A second study, comparing 1,167 people with melanomas to 1,101 who didn't have the cancer, found that using sunscreen routinely, alongside other protection such as hats, long sleeves or staying in the shade, did give some protection. This study said other forms of sun protection-not sunscreen-seemed most beneficial. The study relied on people remembering what they had done over each decade of their lives, so it's not entirely reliable. But it seems reasonable to think sunscreen gives people a false sense of security in the sun.

Many people also don't use sunscreen properly-applying insufficient amounts, failing to reapply after a couple of hours and staying in the sun too long. It is sunburn that is most worrying-recent research shows five episodes of sunburn in the teenage years increases the risk of all skin cancers.

The good news is that a combination of sunscreen and covering up can reduce melanoma rates, as shown by Australian figures from their slip-slop-slap campaign. So if there is a heat wave this summer, it would be best for us, too, to slip on a shirt, slop on (抹上) sunscreen and slap on a hat.

Across the rich world, well-educated people increasingly work longer than the less-skilled. Some 65% of American men aged 62 - 74 with a professional degree are in the workforce, compared with 32% of men with only a high-school certificate. This gap is part of a deepening divide between the well-educated well-off and the unskilled poor. Rapid technological advance has raised the incomes of the highly skilled while squeezing those of the unskilled. The consequences, for individuals and society, are profound.

The world is facing an astonishing rise in the number of old people, and they will live longer than ever before. Over the next 20 years the global population of those aged 65 or more will almost double, from 600 million to 1.1 billion. The experience of the 20th century, when greater longevity (长寿) translated into more years in retirement rather than more years at work, has persuaded many observers that this shift will lead to slower economic growth, while the swelling ranks of pensioners will create government budget problems.

But the notion of a sharp division between the working young and the idle old misses a new trend, the growing gap between the skilled and the unskilled. Employment rates are falling among younger unskilled people, whereas older skilled folk are working longer. The divide is most extreme in America, where well-educated baby-boomers (二战后生育高峰期出生的美国人) are putting off retirement while many less-skilled younger people have dropped out of the workforce.

Policy is partly responsible. Many European governments have abandoned policies that used to encourage people to retire early. Rising life expectancy (预期寿命), combined with the replacement of generous defined-benefit pension plans with less generous defined-contribution ones, means that even the better-off must work longer to have a comfortable retirement. But the changing nature of work also plays a big role. Pay has risen sharply for the highly educated, and those people continue to reap rich rewards into old age because these days the educated elderly are more productive than the preceding generation. Technological change may well reinforce that shift: the skills that complement computers, from management knowhow to creativity, do not necessarily decline with age.

The wallet is heading for extinction. As a day-to-day essential, it will die off with the generation who read print newspapers. The kind of shopping-where you hand over notes and count out change in return-now happens only in the most minor of our retail encounters, like buying a bar of chocolate or a pint of milk from a corner shop. At the shops where you spend any real money, that money is increasingly abstracted. And this is more and more true, the higher up the scale you go. At the most cutting-edge retail stores-Victoria Beckham on Dover Street, for instance-you don't go and stand at any kind of cash register when you decide to pay. The staff are equipped with iPads to take your payment while you relax on a sofa.

Which is nothing more or less than excellent service, if you have the money. But across society, the abstraction of the idea of cash makes me uneasy. Maybe I'm just old-fashioned. But earning money isn't quick or easy for most of us. Isn't it a bit weird that spending it should happen in half a blink (眨眼) of an eye? Doesn't a wallet-that time-honoured Friday-night feeling of pleasing, promising fatness-represent something that matters?

But I'll leave the economics to the experts. What bothers me about the death of the wallet is the change it represents in our physical environment. Everything about the look and feel of a wallet-the way the fastenings and materials wear and tear and loosen with age, the plastic and paper and gold and silver, and handwritten phone numbers and printed cinema tickets-is the very opposite of what our world is becoming. The opposite of a wallet is a smartphone or an iPad. The rounded edges, cool glass, smooth and unknowable as a pebble (鹅卵石). Instead of digging through pieces of paper and peering into comers, we move our fingers left and right. No more counting out coins. Show your wallet, if you still have one. It may not be here much longer.

Everybody sleeps, but what people stay up late to catch-or wake up early in order not to miss?varies by culture.

From data collected, it seems the things that cause us to lose the most sleep, on average, are sporting events, time changes, and holidays.

Around the world, people changed sleep patterns thanks to the start or end of daylight savings time. Russians, for example, began to wake up about a half-hour later each day after President Vladimir Putin shifted the country permanently to "winter time" starting on October 26.

Russia's other late nights and early mornings generally correspond to public holidays. On New Year's Eve, Russians have the world's latest bedtime, hitting the hay at around 3:30 a. m.

Russians also get up an hour later on International Women's Day, the day for treating and celebrating female relatives.

Similarly, Americans' late nights, late mornings, and longest sleeps fall on three-day weekends. 

Canada got the least sleep of the year the night it beat Sweden in the Olympic hockey (冰球) final. 

The World Cup is also chiefly responsible for sleep deprivation (剥夺). The worst night for sleep in the U. K. was the night of the England-Italy match on June 14. Brits stayed up a half-hour later to watch it, and then they woke up earlier than usual the next morning thanks to summer nights, the phenomenon in which the sun barely sets in northern countries in the summertime. That was nothing, though, compared to Germans, Italians, and the French, who stayed up around an hour and a half later on various days throughout the summer to watch the Cup.

It should be made clear that not everyone has a device to record their sleep patterns; in some of these nations, it's likely that only the richest people do. And people who elect to track their sleep may try to get more sleep than the average person. Even if that's the case, though, the above findings are still striking. If the most health-conscious among us have such deep swings in our shut-eye levels throughout the year, how much sleep are the rest of us losing?

When it's five o'clock, people leave their office. The length of the workday, for many workers, is defined by time. They leave when the clock tells them they're done.

These days, the time is everywhere-, not just on clocks or watches, but on cell-phones and computers. That may be a bad thing, particularly at work. New research shows that clock-based work schedules hinder morale (士气) and creativity.

Clock-timers organize their day by blocks of minutes and hours. For example: a meeting from 9 a. m. to 10 a. m. , research from 10 a. m. to noon, etc. On the other hand, task-timers have a list of things they want to accomplish. They work down the list, each task starts when the previous task is completed. It is said that all of us employ a mix of both these types of planning.

What, then, are the effects of thinking about time in these different ways? Does one make us more productive? Better at the tasks at hand? Happier? In experiments conducted by Tamar Avnet and Anne-Laure Sellier, they had participants organize different activities—from project planning, holiday shopping, to yoga—by time or to-do list to measure how they performed under "clock time" vs "task time. " They found clock timers to be more efficient but less happy because they felt little control Over their lives. Task timers are happier and more creative, but less productive. They tend to enjoy the moment when something good is happening, and seize opportunities that come up.

The researchers argue that task-based organizing tends to be undervalued and under-supported in business culture. Smart companies, they believe, will try to bake more task-based planning into their strategies.

This might be a small change to the way we view work and the office, but the researchers argue that it challenges a widespread characteristic of the economy: work organized by clock time. While most people will still probably need, and be, to some extent, clock-timers, task-based timing should be used when performing a job that requires more creativity. It'll make those tasks easier, and the task-doers will be happier.

Martha Stewart was charged, tried and convicted of a crime in 2004. As she neared the end of her prison sentence, a well-known columnist wrote that she was " paying her dues," and that " there is simply no reason for anyone to attempt to deny her right to start anew. "

Surely, the American ideal of second chances should not be reserved only for the rich and powerful. Unfortunately, many federal and state laws impose post-conviction restrictions on a shockingly large number of Americans, who are prevented from ever fully paying their debt to society.

At least 65 million people in the United States have a criminal record. This can result in severe penalties that continue long after punishment is completed.

Many of these penalties are imposed regardless of the seriousness of the offense or the person's individual circumstances. Laws can restrict or ban voting, access to public housing, and professional and business licensing. They can affect a person's ability to get a job and qualification for benefits.

In all, more than 45,000 laws and rules serve to exclude vast numbers of people from fully participating in American life.

Some laws make sense. No one advocates letting someone convicted of pedophilia(恋童癖) work in a school. But too often collateral (附随的) consequences bear no relation to public safety. Should a woman who possessed a small amount of drugs years ago be permanently unable to be licensed as a nurse?

These laws are also counterproductive, since they make it harder for people with criminal records to find housing or land a job, two key factors that reduce backsliding.

A recent report makes several recommendations, including the abolition of most post-conviction penalties, except for those specifically needed to protect public safety. Where the penalties are not a must, they should be imposed only if the facts of a case support it.

The point is not to excuse or forget the crime. Rather, it is to recognize that in America's vast criminal justice system, second chances are crucial. It is in no one's interest to keep a large segment of the population on the margins of society.

Children are a delight. They are our future. But sadly, hiring someone to take care of them while you go to work is getting more expensive by the year.
Earlier this month, it was reported that the cost of enrolling an infant or small kid at a childcare center rose 3% in 2012, faster than the overall cost of living. There are now large strips of the country where daycare for an infant costs more than a tenth of the average married couple's income.
This is not necessarily a new trend, but it is a somewhat puzzling one. The price of professional childcare has been rising since the 1980s. Yet during that time, pay for professional childcare workers has stood still. Actually caregivers make less today, in real terms, than they did in 1990. Considering that labor costs are responsible for up to 80% of a daycare center's expenses, one would expect flat wages to have meant flat prices.
So who's to blame for higher childcare costs?
Childcare is a carefully regulated industry. States lay down rules about how many children each employee is allowed to watch over, the space care centers need per child, and other minute details. And the stricter the regulations, the higher the costs. If it has to hire a caregiver for every two children, it can't really achieve any economies of scale on labor to save money when other expenses go up. In Massachusetts, where childcare centers must hire one teacher for every three infants, the price of care averaged more than $16,000 per year. In Mississippi, where centers must hire one teacher for every five infants, the price of care averaged less than $5,000.
Unfortunately, I don't have all the daycare-center regulations handy. But I wouldn't be surprised if as the rules have become more elaborate, prices have risen. The tradeoff (交换) might be worth it in some cases; after all, the health and safety of children should probably come before cheap service. But certainly, it doesn't seem to be an accident that some of the cheapest daycare available is in the least regulated South.

Alex Pang's amusing new book The Distraction Addiction addresses those of us who feel panic without a cellphone or computer. And that, he claims, is pretty much all of us. When we're not online, where we spend four months annually, we're engaged in the stressful work of trying to get online.
The Distraction Addiction is not framed as a self-help book. It's a thoughtful examination of the danger of our computing overdose and a historical overview of how technological advances change consciousness. A "professional futurist", Pang urges an approach which he calls "contemplative (沉思的) computing." He asks that you pay full attention to "how your mind and body interact with computers and how your attention and creativity are influenced by technology."
Pang's first job is to free you from common misconception that doing two things at once allows you to get more done. What is commonly called multitasking is, in fact, switch-tasking, and its harmful effects on productivity are well documented. Pang doesn't advocate returning to a preinternet world. Instead, he asks you to "take a more ecological (生态的) view of your relationships with technologies and look for ways devices or media may be making specific tasks easier or faster but at the same time making your work and life harder."
The Distraction Addiction is particularly fascinating on how technologies have changed certain field of labor—often for the worse. For architects, computer-aided design has become essential but in some ways has cheapened the design process. As one architect puts it, "Architecture is first and foremost about thinking... and drawing is a more productive way of thinking" than computer-aided design. Somewhat less amusing are Pang's solutions for kicking the Internet habit. He recommends the usual behavior-modification approaches, familiar to anyone who has completed a quit-smoking program. Keep logs to study your online profile and decide what you can knock out, download a program like Freedom that locks you out of your browser, or take a "digital Sabbath (安息日)" ; "Unless you're a reporter or emergency-department doctor, you'll discover that your world doesn't fall apart when you go offline."

